\section{Installation Instructions}

Start by cloning the GitHub repository:

\begin{lstlisting}
cd ~/Projects
git clone https://github.com/Adamouization/Breast-Cancer-Detection-Code
\end{lstlisting}

Create a repository that will be used to install Tensorflow 2 with CUDA 10 for Python and activate the virtual environment for GPU usage:

\begin{lstlisting}
cd libraries/tf2
tar xvzf tensorflow2-cuda-10-1-e5bd53b3b5e6.tar.gz
sh build.sh
\end{lstlisting}

Activate the virtual environment:

\begin{lstlisting}
source /Breast-Cancer-Detection-Code/tf2/venv/bin/activate
\end{lstlisting}

`cd` into the `src` directory and run the code:

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Individual Code Instructions}

Run the code:

\begin{lstlisting}
main.py [-h] -d DATASET [-mt MAMMOGRAMTYPE] -m MODEL [-r RUNMODE] [-b BATCHSIZE] [-e1 MAX_EPOCH_FROZEN] [-e2 MAX_EPOCH_UNFROZEN] [-gs] [-v]
\end{lstlisting}

where:
\begin{itemize}
    \item \textit{-h} is a  flag for help on how to run the code.
    \item \textit{DATASET} is the dataset to use. Must be either \textit{mini-MIAS} or \textit{CBIS-DDMS}.
    \item \textit{MAMMOGRAMTYPE} is the type of mammogram to use. Can be either \textit{calc}, \textit{mass} or \textit{all}.
    \item \textit{MODEL} is the model to use. Must be either \textit{VGG}, \textit{ResNet}, \textit{Inception} or \textit{Xception}. Default value is \textit{VGG}.
    \item \textit{RUNMODE} is the mode to run in (\textit{train} or \textit{test}). Default value is \textit{train}.
    \item \textit{BATCHSIZE} is the batch size to use when training the model. Defaults to \textit{2}.
    \item \textit{MAXEPOCHFROZEN} is the maximum number of epochs in the first training phrase (with frozen layers). Defaults to \textit{100}.
    \item \textit{MAXEPOCHUNFROZEN} is the maximum number of epochs in the second training phrase (with unfrozen layers). Defaults to \textit{50}.
    \item \textit{-gs} is a flag to run the grid search algorithm to determine the optimal hyperparameters for the CNN model.
    \item \textit{-v} is a flag controlling verbose mode, which prints additional statements for debugging purposes.
\end{itemize}

Set the \textit{PYTHONHASHSEED} environment variable to 0 before the program starts for reproducible results (e.g. when using hash-based operations):

\begin{lstlisting}
PYTHONHASHSEED=0 main.py [...]
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Common Pipeline Code Instructions}

Run the code:

\begin{lstlisting}
python main.py [-h] -d DATASET -m MODEL [-r RUNMODE] [-i IMAGESIZE] [-v]
\end{lstlisting}

where:
\begin{itemize}
    \item \textit{-h} is a  flag for help on how to run the code.
    \item \textit{DATASET} is the dataset to use. Must be either \textit{mini-MIAS} or \textit{CBIS-DDMS}.
    \item \textit{MODEL} is the model to use. Must be either \textit{basic} or \textit{advanced}.
    \item \textit{RUNMODE} is the mode to run in (\textit{train} or \textit{test}). Default value is \textit{train}.
    \item \textit{IMAGESIZE} is the image size to feed into the CNN model (\textit{small} - 512x512px; or \textit{large} - 2048x2048px). Default value is \textit{small}.
    \item \textit{-v} is a flag controlling verbose mode, which prints additional statements for debugging purposes.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Dataset Installation Instructions}

\subsection{mini-MIAS dataset}

This example will use the mini-MIAS dataset\footnote{mini-MIAS dataset: \url{http://peipa.essex.ac.uk/info/mias.html}}. After cloning the project, travel to the \textit{data/mini-MIAS} directory (there should be 3 files in it).\\

Create \textit{images\_original} and \textit{images\_processed} directories in this directory: 

\begin{lstlisting}
cd data/mini-MIAS/
mkdir images_original
mkdir images_processed
\end{lstlisting}

Move to the \textit{images\_original} directory and download the raw un-processed images:

\begin{lstlisting}
cd images_original
wget http://peipa.essex.ac.uk/pix/mias/all-mias.tar.gz
\end{lstlisting}

Unzip the dataset then delete all non-image files:

\begin{lstlisting}
tar xvzf all-mias.tar.gz
rm -rf *.txt 
rm -rf README 
\end{lstlisting}

Move back up one level and move to the \textit{images\_processed} directory. Create 3 new directories there (\textit{benign\_cases}, \textit{malignant\_cases} and \textit{normal\_cases}):

\begin{lstlisting}
cd ../images_processed
mkdir benign_cases
mkdir malignant_cases
mkdir normal_cases
\end{lstlisting}

Now run the python script for processing the dataset and render it usable with Tensorflow and Keras:

\begin{lstlisting}
python3 ../../../src/data_manipulations/mini-MIAS-initial-pre-processing.py
\end{lstlisting}

\subsection{CBIS-DDSM dataset}

These datasets are very large (exceeding 160GB) and more complex than the mini-MIAS dataset to use. They were downloaded by the University of St Andrews School of Computer Science computing officers onto \textit{BigTMP}, a 15TB filesystem that is mounted on the Centos 7 computer lab clients with NVIDIA GPUs, and that is usually used for storing large working data sets. Therefore, downloading and these datasets them will not be covered by these instructions.\\

Our generated CSV files to use these datasets can be found in the \textit{/data/CBIS-DDSM} directory, but the mammograms will have to be downloaded separately directly from the source. The CBIS-DDSM dataset can be downloaded here: \url{https://wiki.cancerimagingarchive.net/display/Public/CBIS-DDSM#5e40bd1f79d64f04b40cac57ceca9272}.
